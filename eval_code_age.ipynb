{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JkjZfvuKHd6q"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dataloader import BatchDataloader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import h5py\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from utils import pgd_attack, eval_loop, eval_loop_apgd, filter_adversarial\n",
    "from models import ResNet1dGELU\n",
    "import ecg_plot\n",
    "from utils import plot_ecgs\n",
    "import ast\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tqdm.write(\"Use device: {device:}\\n\".format(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 13892, 1: 20577}\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "dataset_path = '/local_storage/users/arveri/code-15'\n",
    "\n",
    "path_to_csv = dataset_path + '/exams.csv'\n",
    "path_to_val = dataset_path + '/test.h5'\n",
    "path_to_train = dataset_path + '/train10.h5'\n",
    "\n",
    "# Get labels\n",
    "df = pd.read_csv(path_to_csv, index_col='exam_id')\n",
    "\n",
    "# Get h5 file\n",
    "train_file = h5py.File(path_to_train, 'r')\n",
    "train_traces_ids = train_file['exam_id']\n",
    "\n",
    "val_file = h5py.File(path_to_val, 'r')\n",
    "val_traces_ids = val_file['exam_id']\n",
    "\n",
    "# Only keep the traces in the csv that match the traces in the h5 file\n",
    "train_df = df[df.index.isin(train_traces_ids)]\n",
    "val_df = df[df.index.isin(val_traces_ids)]\n",
    "\n",
    "# Define traces\n",
    "train_traces = train_file['tracings']\n",
    "val_traces = val_file['tracings']\n",
    "\n",
    "# Sort the dataframe in trace order\n",
    "train_df = train_df.reindex(train_traces_ids)\n",
    "val_df = val_df.reindex(val_traces_ids)\n",
    "\n",
    "# Get labels\n",
    "train_labels = train_df['age'].values\n",
    "val_labels = val_df['age'].values\n",
    "\n",
    "# Only use x% of the training data\n",
    "train_traces = train_traces#[:len(train_traces)//div]\n",
    "train_labels = train_labels#[:len(train_labels)//div]\n",
    "\n",
    "# Count each label\n",
    "unique, counts = np.unique(val_labels, return_counts=True)\n",
    "\n",
    "# Print it\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "print(dict(zip(unique_train, counts_train)))\n",
    "\n",
    "# Print size of training and validation set\n",
    "print(f\"Training set size: {len(train_labels)}\")\n",
    "print(f\"Validation set size: {len(val_labels)}\")\n",
    "\n",
    "# Make into torch tensor\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32).reshape(-1,1)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "# Define dataloaders\n",
    "train_dataloader = BatchDataloader(train_traces, train_labels, batch_size=batch_size)\n",
    "val_dataloader = BatchDataloader(val_traces, val_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boot = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948f82e1d4994b058ca1ab9fee380e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Epoch  0:   0%|          | 0/1078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556c4f43310d492e83da5f595e926315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Epoch  0:   0%|          | 0/1078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e85e13ef1f4df095beab1e3a12ba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Epoch  0:   0%|          | 0/1078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Create dictionary for storing metrics for each model\n",
    "metrics = {}\n",
    "\n",
    "for model_path in [\"../models/age/ptb_20_apgd_1e-2_code15_lr1e-4_div1/latest.pth\", \"../models/age/ptb_20_apgd_5e-2_code15_lr1e-4_div1/latest.pth\", \"../models/age/ptb_20_code15_lr1e-4_div1/latest.pth\"]:\n",
    "    # Define the model\n",
    "    model = ResNet1dGELU(input_dim=(12, 4096),n_classes=1, blocks_dim=[(64, 4096), (128, 1024), (196, 256), (256, 64), (320, 16)])#, kernel_size=3, dropout_rate=0.8\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.to(device)\n",
    "    \n",
    "    metrics[model_path] = {}\n",
    "    \n",
    "    valid_loss, y_pred, y_true = eval_loop(0, val_dataloader, model, loss_function, device)\n",
    "    \n",
    "    # save y_pred and y_true to same directory as model\n",
    "    path = model_path.split('.pth')[0]\n",
    "    \n",
    "    with open(path + '_y_pred.npy', 'wb') as f:\n",
    "        np.save(f, y_pred)\n",
    "    with open(path + '_y_true.npy', 'wb') as f:\n",
    "        np.save(f, y_true)\n",
    "\n",
    "    # bootstrap!!!\n",
    "\n",
    "    # def bootstrap(y_test, y_pred, metric, quantiles, n_boot=500):\n",
    "    bootstrapped_maes = np.zeros(n_boot)\n",
    "    bootstrapped_mses = np.zeros(n_boot)\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        indices = np.random.choice(range(len(y_pred)), len(y_pred))\n",
    "        bootstrapped_maes[i] = mean_absolute_error(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_mses[i] = mean_squared_error(y_true[indices], y_pred[indices])\n",
    "\n",
    "    mae_q1 = np.quantile(bootstrapped_maes, 0.25)\n",
    "    mae_q3 = np.quantile(bootstrapped_maes, 0.75)\n",
    "    mae_med = np.median(bootstrapped_maes)\n",
    "\n",
    "    mse_q1 = np.quantile(bootstrapped_mses, 0.25)\n",
    "    mse_q3 = np.quantile(bootstrapped_mses, 0.75)\n",
    "    mse_med = np.median(bootstrapped_mses)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    # store the metrics for this model\n",
    "    metrics[model_path] = {'mae': mae, 'mse': mse, 'mae_q1': mae_q1, 'mae_q3': mae_q3, 'mae_med': mae_med, 'mse_q1': mse_q1, 'mse_q3': mse_q3, 'mse_med': mse_med}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                                                       Accuracy     AUROC        AP    Max F1\n",
      "--------------------------------------------------------  ----------  --------  --------  --------\n",
      "../models/sex/ptb_20_code15ft_div10/latest.pth              0.781949  0.849451  0.869388  0.832831\n",
      "../models/sex/ptb_20_apgd_5e-2_code15ft_div10/latest.pth    0.767356  0.837207  0.872097  0.820666\n",
      "../models/sex/ptb_20_apgd_1e-2_code15ft_div10/latest.pth    0.778148  0.850438  0.884768  0.828249\n"
     ]
    }
   ],
   "source": [
    "# Print table comparing results\n",
    "from tabulate import tabulate\n",
    "\n",
    "table = []\n",
    "\n",
    "for model_path, model_metrics in metrics.items():\n",
    "    table.append([model_path, model_metrics['mae'], model_metrics['mae_q1'], model_metrics['mae_q3'], model_metrics['mae_med'], model_metrics['mse'], model_metrics['mse_q1'], model_metrics['mse_q3'], model_metrics['mse_med']])\n",
    "    \n",
    "print(tabulate(table, headers=['Model', 'MAE', 'MAE Q1', 'MAE Q3', 'MAE Median', 'MSE', 'MSE Q1', 'MSE Q3', 'MSE Median']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/model_latest_20_fine_tunedlr1e-3/latest.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_path \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/model_latest_20_fine_tunedlr1e-3/latest.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m ResNet1dGELU(input_dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4096\u001b[39m),n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, blocks_dim\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m4096\u001b[39m), (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1024\u001b[39m), (\u001b[38;5;241m196\u001b[39m, \u001b[38;5;241m256\u001b[39m), (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m64\u001b[39m), (\u001b[38;5;241m320\u001b[39m, \u001b[38;5;241m16\u001b[39m)])\u001b[38;5;66;03m#, kernel_size=3, dropout_rate=0.8\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/mambaforge/envs/wasp/lib/python3.9/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/mambaforge/envs/wasp/lib/python3.9/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/mambaforge/envs/wasp/lib/python3.9/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/model_latest_20_fine_tunedlr1e-3/latest.pth'"
     ]
    }
   ],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Create dictionary for storing metrics for each model\n",
    "metrics = {}\n",
    "\n",
    "# Test for different epsilon values\n",
    "eps_list = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "for model_path in [\"models/model_latest_20_fine_tunedlr1e-3/latest.pth\"]:\n",
    "    # Define the model\n",
    "    model = ResNet1dGELU(input_dim=(12, 4096),n_classes=1, blocks_dim=[(64, 4096), (128, 1024), (196, 256), (256, 64), (320, 16)])#, kernel_size=3, dropout_rate=0.8\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.to(device)\n",
    "    \n",
    "    metrics[model_path] = {}\n",
    "    \n",
    "    for eps in eps_list:\n",
    "        # Evaluate with adversarial examples\n",
    "        adv_valid_loss, adv_y_pred, adv_y_true = eval_loop_apgd(0, val_dataloader, model, loss_function, device, adversarial=True, adv_eps=eps, adv_iters=10, adv_restarts=1)\n",
    "        \n",
    "        # apply sigmoid to y_pred\n",
    "        adv_y_pred = torch.sigmoid(torch.tensor(adv_y_pred)).numpy()\n",
    "            \n",
    "        adv_auroc = roc_auc_score(adv_y_true, adv_y_pred)\n",
    "        adv_ap = average_precision_score(adv_y_true, adv_y_pred)\n",
    "        \n",
    "        # compute max F1 score (over threshold)\n",
    "        thresholds = np.linspace(0, 1, 100)\n",
    "        f1_scores = [f1_score(adv_y_true, adv_y_pred > threshold, average='binary') for threshold in thresholds]\n",
    "        best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        best_f1 = np.max(f1_scores)\n",
    "        \n",
    "        adv_y_pred = np.round(adv_y_pred)\n",
    "\n",
    "        # compute accuracy\n",
    "        adv_accuracy = accuracy_score(adv_y_true, adv_y_pred)\n",
    "        adv_f1 = f1_score(adv_y_true, adv_y_pred, average='binary')\n",
    "        \n",
    "        # store the metrics for this model\n",
    "        metrics[model_path][eps] = {'accuracy': adv_accuracy, 'auroc': adv_auroc, 'ap': adv_ap, 'max f1': best_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save these metrics to a file\n",
    "for model_path, model_metrics in metrics.items():\n",
    "    save_path = model_path.replace('.pth', '_apgd_eval.json')\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(model_metrics, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model metrics \n",
    "import json\n",
    "\n",
    "loaded_metrics = {}\n",
    "for model_path in ['models/code_model_10/latest.pth', 'models/model_latest_adv_20_0.01exp_apgd_fine_tunedlr1e-3/latest.pth', 'models/model_latest_adv_20_0.01exp_apgd_fine_tunedlr1e-3ep20/latest.pth']:\n",
    "    with open(model_path.replace('.pth', '_apgd_eval.json'), 'r') as f:\n",
    "        loaded_metrics[model_path] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from importlib import reload\n",
    "import autopgd_base\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib as mpl\n",
    "plt.style.use(['style.mpl'])\n",
    "\n",
    "# plot the accuracy for each model and each epsilon\n",
    "labels = ['model 1', 'model 2', 'model 3']\n",
    "colors = ['blue', 'red', 'green']\n",
    "linestyles = ['-', '--', '-.']\n",
    "eps_list = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "for model_path, color, linestyle, label in zip(loaded_metrics, colors, linestyles, labels):\n",
    "    # get the metrics for this model\n",
    "    model_metrics = loaded_metrics[model_path]\n",
    "    \n",
    "    # get the accuracy for each epsilon\n",
    "    acc = [model_metrics[eps]['ap'] for eps in model_metrics]\n",
    "    \n",
    "    # plot the accuracy\n",
    "    plt.plot([str(eps) for eps in eps_list], acc, label=label, marker='o', linestyle=linestyle, linewidth=1, color=color)\n",
    "    \n",
    "plt.grid()\n",
    "\n",
    "# change figure size\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6, 4)\n",
    "\n",
    "# make it higher resolution\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Set font size\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# set remaining fonts such as axis and legend\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('$\\epsilon$', fontsize=12)\n",
    "plt.ylabel('AUPRC', fontsize=12)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the f1 score for each model and each epsilon\n",
    "for model_path in metrics:\n",
    "    # get the metrics for this model\n",
    "    model_metrics = metrics[model_path]\n",
    "    \n",
    "    # get the accuracy for each epsilon\n",
    "    f1 = [model_metrics[eps]['f1'] for eps in model_metrics]\n",
    "    \n",
    "    # plot the accuracy\n",
    "    plt.plot([str(eps) for eps in eps_list], f1, label=model_path, marker='o')\n",
    "    \n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('F1 score')\n",
    "plt.grid()\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet1dGELU(input_dim=(12, 4096),n_classes=1, blocks_dim=[(64, 4096), (128, 1024), (196, 256), (256, 64), (320, 16)])#, kernel_size=3, dropout_rate=0.8\n",
    "checkpoint = torch.load(\"model_latest_adv_20_5e-2exp.pth\", map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model = model.to(device)\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from importlib import reload\n",
    "import autopgd_base\n",
    "\n",
    "reload(utils)\n",
    "reload(autopgd_base)\n",
    "\n",
    "eps = 5e-2\n",
    "cuttoff_freq = 150\n",
    "\n",
    "# Plot some adversarial examples\n",
    "traces, diagnoses = next(iter(val_dataloader))\n",
    "\n",
    "ecg_sample = np.transpose(traces[0])\n",
    "\n",
    "traces = traces.to(device)\n",
    "diagnoses = diagnoses.to(device)\n",
    "\n",
    "# TEST APGD\n",
    "# import apgd\n",
    "# attack = apgd.APGD(model, norm='Linf', eps=1e-3, steps=10, n_restarts=1, seed=0, loss='bce', eot_iter=1, rho=.75, verbose=False)\n",
    "# traces = attack(traces, diagnoses)\n",
    "diagnoses = diagnoses.reshape(-1)\n",
    "\n",
    "\n",
    "print(traces.shape)\n",
    "print(diagnoses.shape)\n",
    "\n",
    "attack = autopgd_base.APGDAttack(model, n_iter=20, norm='Linf', n_restarts=1, eps=eps, seed=0, loss='ce', eot_iter=1, rho=.75)\n",
    "attack.init_hyperparam(traces)\n",
    "attack.attack_single_run(traces, diagnoses)\n",
    "\n",
    "\n",
    "traces = pgd_attack(model, traces, diagnoses, device, eps=eps, alpha=eps/5, steps=10)\n",
    "\n",
    "ecg_sample_adv = np.transpose(traces[0].cpu().numpy())\n",
    "\n",
    "# Filter it\n",
    "ecg_sample_adv = filter_adversarial(ecg_sample_adv, sample_rate=400, fc=cuttoff_freq)\n",
    "\n",
    "\n",
    "# Select the first lead\n",
    "ecg_sample = ecg_sample[0:1]\n",
    "\n",
    "ecg_sample_adv = ecg_sample_adv[0:1]\n",
    "\n",
    "plt.figure()\n",
    "#lead = ['I', 'II', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'I-adv', 'II-adv', 'V1-adv', 'V2-adv', 'V3-adv', 'V4-adv', 'V5-adv', 'V6-adv']\n",
    "lead = ['I', 'I-adv', 'II', 'II-adv', 'V1', 'V1-adv', 'V2', 'V2-adv', 'V3', 'V3-adv', 'V4', 'V4-adv', 'V5', 'V5-adv', 'V6', 'V6-adv']\n",
    "#lead = ['I', 'I-adv']\n",
    "utils.plot_ecgs(ecg_sample, ecg_sample_adv, sample_rate=400, style = 'bw', row_height=6, lead_index=lead, columns=1, title=\"\",show_zoom=True, zoom_box=[3.0, 4.0, -0.2, 0.3], zoom_rate=10)\n",
    "plt.legend(['Adversarial', 'Original'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 5e-2\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "fcs = [1, 2, 5, 10, 20, 50, 75, 100, 125, 150]\n",
    "\n",
    "# Create dictionary for storing metrics for each model\n",
    "metrics = {}\n",
    "\n",
    "for model_path in ['model_latest_20.pth', \"model_latest_adv_20_5e-2exp.pth\"]:\n",
    "    # Define the model\n",
    "    model = ResNet1dGELU(input_dim=(12, 4096),n_classes=1, blocks_dim=[(64, 4096), (128, 1024), (196, 256), (256, 64), (320, 16)])#, kernel_size=3, dropout_rate=0.8\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.to(device)\n",
    "    \n",
    "    metrics[model_path] = {}\n",
    "    \n",
    "    for fc in fcs:\n",
    "        # Evaluate with adversarial examples\n",
    "        adv_valid_loss, adv_y_pred, adv_y_true = eval_loop(0, val_dataloader, model, loss_function, device, adversarial=True, adv_eps=eps, adv_alpha=eps/5, adv_steps=10, post_process=filter_adversarial, post_process_args=[400, fc])\n",
    "\n",
    "        adv_auroc = roc_auc_score(adv_y_true, adv_y_pred)\n",
    "        adv_ap = average_precision_score(adv_y_true, adv_y_pred)\n",
    "\n",
    "        # apply sigmoid to y_pred\n",
    "        adv_y_pred = torch.sigmoid(torch.tensor(adv_y_pred)).numpy()\n",
    "        adv_y_pred = np.round(adv_y_pred)\n",
    "\n",
    "        # compute accuracy\n",
    "        adv_accuracy = accuracy_score(adv_y_true, adv_y_pred)\n",
    "        adv_f1 = f1_score(adv_y_true, adv_y_pred, average='binary')\n",
    "        \n",
    "        # store the metrics for this model\n",
    "        metrics[model_path][fc] = {'accuracy': adv_accuracy, 'auroc': adv_auroc, 'ap': adv_ap, 'f1': adv_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ap for each model and each epsilon\n",
    "for model_path in metrics:\n",
    "    # get the metrics for this model\n",
    "    model_metrics = metrics[model_path]\n",
    "    \n",
    "    # get the accuracy for each epsilon\n",
    "    ap = [model_metrics[fc]['ap'] for fc in model_metrics]\n",
    "    \n",
    "    # plot the accuracy\n",
    "    plt.plot([str(fc) for fc in fcs], ap, label=model_path, marker='o')\n",
    "\n",
    "plt.xlabel('Cutoff frequency')\n",
    "plt.ylabel('AUPRC')\n",
    "plt.grid()\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "assignment_ecg_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
